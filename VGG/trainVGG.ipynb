{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # 不使用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from VGGModel import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.abspath(os.path.join(os.getcwd(),\"../../datasets\"))\n",
    "image_path = data_root+\"/flower_data/\"\n",
    "train_dir = image_path+'train'\n",
    "validation_dir = image_path+'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height=224\n",
    "im_width =224\n",
    "batch_size=32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3306 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# 论文里有去均值的预处理，这里没有是因为从头开始训练的不是迁移学习\n",
    "# ImageNet RGB三通道均值是[123.68,116.78,103.94]\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255.,horizontal_flip=True)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=True,\n",
    "                                                          target_size=(im_height,im_width),\n",
    "                                                          class_mode = 'categorical')\n",
    "total_train=train_data_gen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_indices = train_data_gen.class_indices\n",
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_dict = dict((val,key) for key,val in class_indices.items())\n",
    "\n",
    "json_str = json.dumps(inverse_dict,indent=4)\n",
    "with open('class_indices.json','w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 364 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = train_image_generator.flow_from_directory(directory=validation_dir,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        target_size=(im_height,im_width),\n",
    "                                                        class_mode='categorical')\n",
    "total_val=val_data_gen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "feature (Sequential)         (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              51382272  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 10245     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 70,303,557\n",
      "Trainable params: 70,303,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg('vgg16',224,224,5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./save_weights/myVGG_{epoch}.h5',\n",
    "                                               save_best_only=True,\n",
    "                                               save_weights_only=True,\n",
    "                                               monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_data_gen,\n",
    "                   steps_per_epoch=total_train//batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=val_data_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
