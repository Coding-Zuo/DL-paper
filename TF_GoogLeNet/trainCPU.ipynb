{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Model.ipynb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import import_ipynb\n",
    "from Model import GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.abspath(os.path.join(os.getcwd(),\"../../datasets\"))\n",
    "image_path = data_root+\"/flower_data/\"\n",
    "train_dir = image_path+'train'\n",
    "validation_dir = image_path+'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('save_weights'):\n",
    "    os.mkdir('save_weights')\n",
    "im_height=224\n",
    "im_width =224\n",
    "batch_size=32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_function(img):\n",
    "    img = img/255.\n",
    "    img = (img-0.5)*2.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3306 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(preprocessing_function=pre_function,\n",
    "                                          horizontal_flip=True)\n",
    "validation_image_generator = ImageDataGenerator(preprocessing_function=pre_function)\n",
    "\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=True,\n",
    "                                                          target_size=(im_height,im_width),\n",
    "                                                          class_mode='categorical')\n",
    "total_train = train_data_gen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_indices = train_data_gen.class_indices\n",
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_dict = dict((val,key) for key,val in class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(inverse_dict,indent=4)\n",
    "with open('class_indices.json','w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 364 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(directory=validation_dir,\n",
    "                                                             batch_size=batch_size,\n",
    "                                                             shuffle=False,\n",
    "                                                             target_size=(im_height,im_width),\n",
    "                                                             class_mode='categorical')\n",
    "total_val = val_data_gen.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-723a27c4b686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.build((batch_size,224,224,3)) # subclass model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zuoyuhui/paper/GoogLeNet/Model.ipynb\u001b[0m in \u001b[0;36mGoogLeNet\u001b[0;34m(im_height, im_width, class_num, aux_logits)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2122\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2123\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         spec.max_ndim is not None):\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[1;32m    165\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model = GoogLeNet(im_height=im_height,im_width=im_width,class_num=5,aux_logits=True)\n",
    "# model.build((batch_size,224,224,3)) # subclass model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images,lables):\n",
    "    with tf.GradientTape() as tape:\n",
    "        aux1,aux2,output = model(images,training=True)\n",
    "        loss1 = loss_object(lables,aux1)\n",
    "        loss2 = loss_object(lables,aux2)\n",
    "        loss3 = loss_object(lables,output)\n",
    "        loss = loss1*0.3 + loss2*0.3 + loss3\n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(lables,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images,labels):\n",
    "    _,_,output = model(images,training=False)\n",
    "    t_loss = loss_object(labels,output)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss:2.195668935775757, Accuracy:35.21685791015625, Test Loss:1.1382713317871094, Test Accuracy:46.306819915771484\n",
      "Epoch 2, Loss:1.7295641899108887, Accuracy:50.97087478637695, Test Loss:0.9794753789901733, Test Accuracy:62.95180892944336\n",
      "Epoch 3, Loss:1.4911433458328247, Accuracy:60.904090881347656, Test Loss:0.8690599799156189, Test Accuracy:64.45783233642578\n",
      "Epoch 4, Loss:1.3782355785369873, Accuracy:64.26390075683594, Test Loss:0.8264938592910767, Test Accuracy:67.77108001708984\n",
      "Epoch 5, Loss:1.2864623069763184, Accuracy:67.56261444091797, Test Loss:0.919053852558136, Test Accuracy:65.66265106201172\n",
      "Epoch 6, Loss:1.2512352466583252, Accuracy:68.87599182128906, Test Loss:0.7279787659645081, Test Accuracy:73.79518127441406\n",
      "Epoch 7, Loss:1.1951675415039062, Accuracy:72.08307647705078, Test Loss:0.7642440795898438, Test Accuracy:70.78313446044922\n",
      "Epoch 8, Loss:1.118859052658081, Accuracy:72.72449493408203, Test Loss:0.7976974248886108, Test Accuracy:70.78313446044922\n",
      "Epoch 9, Loss:1.0620782375335693, Accuracy:74.55712127685547, Test Loss:0.7536340951919556, Test Accuracy:70.78313446044922\n",
      "Epoch 10, Loss:1.0686018466949463, Accuracy:75.2596206665039, Test Loss:0.7879422903060913, Test Accuracy:70.78313446044922\n",
      "Epoch 11, Loss:1.0002797842025757, Accuracy:76.23701477050781, Test Loss:0.7664726376533508, Test Accuracy:75.90361022949219\n",
      "Epoch 12, Loss:0.9563718438148499, Accuracy:77.61148071289062, Test Loss:0.7247485518455505, Test Accuracy:75.60240936279297\n",
      "Epoch 13, Loss:0.8968386054039001, Accuracy:79.2608413696289, Test Loss:0.5625154972076416, Test Accuracy:79.82954406738281\n",
      "Epoch 14, Loss:0.870758593082428, Accuracy:78.92486572265625, Test Loss:0.5581256151199341, Test Accuracy:80.72289276123047\n",
      "Epoch 15, Loss:0.8147966861724854, Accuracy:81.24617767333984, Test Loss:0.6690281629562378, Test Accuracy:78.01204681396484\n",
      "Epoch 16, Loss:0.7983230352401733, Accuracy:81.4599838256836, Test Loss:0.580307126045227, Test Accuracy:80.1204833984375\n",
      "Epoch 17, Loss:0.771430253982544, Accuracy:82.10140228271484, Test Loss:0.5536425113677979, Test Accuracy:79.51807403564453\n",
      "Epoch 18, Loss:0.6873193383216858, Accuracy:84.20891571044922, Test Loss:0.5167847871780396, Test Accuracy:82.22891998291016\n",
      "Epoch 19, Loss:0.7409345507621765, Accuracy:82.55956268310547, Test Loss:0.4958334267139435, Test Accuracy:84.03614044189453\n",
      "Epoch 20, Loss:0.6013174653053284, Accuracy:86.4080581665039, Test Loss:0.7333269715309143, Test Accuracy:78.01204681396484\n",
      "Epoch 21, Loss:0.6686580777168274, Accuracy:84.78924560546875, Test Loss:0.5952565670013428, Test Accuracy:79.51807403564453\n",
      "Epoch 22, Loss:0.5491890907287598, Accuracy:87.35491943359375, Test Loss:0.6028401851654053, Test Accuracy:76.50602722167969\n",
      "Epoch 23, Loss:0.5468771457672119, Accuracy:87.1716537475586, Test Loss:0.6734090447425842, Test Accuracy:81.02410125732422\n",
      "Epoch 24, Loss:0.4604325294494629, Accuracy:89.76786804199219, Test Loss:0.5269966721534729, Test Accuracy:81.02410125732422\n",
      "Epoch 25, Loss:0.44093891978263855, Accuracy:90.31765747070312, Test Loss:0.7149350643157959, Test Accuracy:78.9772720336914\n",
      "Epoch 26, Loss:0.48439326882362366, Accuracy:89.27916717529297, Test Loss:0.6388185024261475, Test Accuracy:80.1204833984375\n",
      "Epoch 27, Loss:0.39715901017189026, Accuracy:91.69212341308594, Test Loss:0.6739597916603088, Test Accuracy:76.8072280883789\n",
      "Epoch 28, Loss:0.36852991580963135, Accuracy:91.35614013671875, Test Loss:0.6173710227012634, Test Accuracy:81.62650299072266\n",
      "Epoch 29, Loss:0.36978453397750854, Accuracy:91.44776916503906, Test Loss:0.6826313138008118, Test Accuracy:78.91566467285156\n",
      "Epoch 30, Loss:0.33965742588043213, Accuracy:92.60842895507812, Test Loss:0.5520007610321045, Test Accuracy:82.53012084960938\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = float('inf')\n",
    "for epoch in range(1,epochs+1):\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for step in range(total_train//batch_size):\n",
    "        images,labels = next(train_data_gen)\n",
    "        train_step(images,labels)\n",
    "        \n",
    "    for step in range(total_val//batch_size):\n",
    "        test_images,test_labels = next(val_data_gen)\n",
    "        test_step(test_images,test_labels)\n",
    "    \n",
    "    template ='Epoch {}, Loss:{}, Accuracy:{}, Test Loss:{}, Test Accuracy:{}'\n",
    "    print(template.format(epoch,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))\n",
    "    if test_loss.result() < best_test_loss:\n",
    "        best_test_loss=test_loss.result()\n",
    "        model.save_weights('./save_weights/myGoogleNetCPU.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
